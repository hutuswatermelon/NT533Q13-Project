from flask import Flask, request, jsonify
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
import os

app = Flask(__name__)

# Kh·ªüi t·∫°o Spark session
spark = SparkSession.builder \
    .appName("ChurnPredictionAPI") \
    .config("spark.hadoop.fs.gs.impl", "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem") \
    .config("spark.hadoop.google.cloud.auth.service.account.enable", "true") \
    .config("spark.hadoop.google.cloud.auth.service.account.json.keyfile", "/home/caphuutu2005/key.json") \
    .getOrCreate()

# üìå ƒê∆∞·ªùng d·∫´n t·ªõi m√¥ h√¨nh ƒë√£ train v√† l∆∞u tr√™n GCS
MODEL_PATH = "gs://nt533q13-spark-data/models/telco_rf"

print("üîπ ƒêang load m√¥ h√¨nh...")
model = PipelineModel.load(MODEL_PATH)
print("‚úÖ Load m√¥ h√¨nh th√†nh c√¥ng!")

@app.route("/predict", methods=["POST"])
def predict():
    try:
        data = request.get_json()

        # Convert JSON sang Spark DataFrame
        df = spark.createDataFrame([data])

        # D·ª± ƒëo√°n
        prediction = model.transform(df).collect()[0]
        label = prediction["prediction"]
        prob = prediction["probability"][1]  # x√°c su·∫•t churn

        return jsonify({
            "churn_prediction": int(label),
            "churn_probability": float(prob)
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/health", methods=["GET"])
def health():
    return "OK", 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=80)
