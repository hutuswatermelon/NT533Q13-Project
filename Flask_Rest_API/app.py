from flask import Flask, request, jsonify
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel

app = Flask(__name__)

# Khá»Ÿi táº¡o Spark session, dÃ¹ng ADC (Application Default Credentials)
spark = SparkSession.builder \
    .appName("ChurnPredictionAPI") \
    .config("spark.hadoop.fs.gs.impl", "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem") \
    .getOrCreate()

# ğŸ“Œ ÄÆ°á»ng dáº«n tá»›i mÃ´ hÃ¬nh Ä‘Ã£ train vÃ  lÆ°u trÃªn GCS
MODEL_PATH = "gs://nt533q13-spark-data/models/telco_rf"

print("ğŸ”¹ Äang load mÃ´ hÃ¬nh...")
model = PipelineModel.load(MODEL_PATH)
print("âœ… Load mÃ´ hÃ¬nh thÃ nh cÃ´ng!")

@app.route("/predict", methods=["POST"])
def predict():
    try:
        data = request.get_json()

        # Convert JSON sang Spark DataFrame
        df = spark.createDataFrame([data])

        # Dá»± Ä‘oÃ¡n
        prediction = model.transform(df).collect()[0]
        label = prediction["prediction"]
        prob = prediction["probability"][1]  # xÃ¡c suáº¥t churn

        return jsonify({
            "churn_prediction": int(label),
            "churn_probability": float(prob)
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/health", methods=["GET"])
def health():
    return "OK", 200

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
